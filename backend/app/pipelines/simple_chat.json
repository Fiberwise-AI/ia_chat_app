{
    "name": "Simple Chat Pipeline",
    "description": "LLM chat with history and conditional title generation for first message",
    "version": "3.0.0",
    "parameters": [
        {
            "name": "message",
            "schema": {"type": "string"},
            "required": true,
            "description": "User message"
        },
        {
            "name": "session_id",
            "schema": {"type": "string"},
            "required": false,
            "description": "Chat session ID (null for new chat)"
        },
        {
            "name": "system_prompt",
            "schema": {"type": "string"},
            "required": false,
            "description": "System prompt to guide the assistant's behavior"
        }
    ],
    "steps": [
        {
            "id": "fetch_history",
            "name": "Fetch Chat History",
            "step_class": "FetchChatHistoryStep",
            "module": "app.pipeline_steps.fetch_chat_history_step",
            "config": {},
            "inputs": [
                {
                    "name": "session_id",
                    "source": "{parameters.session_id}",
                    "schema": {"type": "string"},
                    "required": false
                }
            ],
            "outputs": [
                {
                    "name": "chat_history",
                    "schema": {"type": "array"},
                    "required": true,
                    "description": "Array of {role, content} message objects"
                },
                {
                    "name": "message_count",
                    "schema": {"type": "integer"},
                    "required": true,
                    "description": "Total number of messages in this session"
                },
                {
                    "name": "is_first_message",
                    "schema": {"type": "boolean"},
                    "required": true,
                    "description": "Whether this is the first message (message_count == 0)"
                }
            ]
        },
        {
            "id": "fetch_documents",
            "name": "Fetch Documents",
            "step_class": "FetchDocumentsStep",
            "module": "app.pipeline_steps.fetch_documents_step",
            "config": {},
            "inputs": [
                {
                    "name": "session_id",
                    "source": "{parameters.session_id}",
                    "schema": {"type": "string"},
                    "required": false
                }
            ],
            "outputs": [
                {
                    "name": "documents",
                    "schema": {"type": "array"},
                    "required": true,
                    "description": "List of document metadata"
                },
                {
                    "name": "document_context",
                    "schema": {"type": "string"},
                    "required": true,
                    "description": "Formatted document content for LLM context with chunk IDs"
                },
                {
                    "name": "document_count",
                    "schema": {"type": "integer"},
                    "required": true,
                    "description": "Number of documents attached"
                },
                {
                    "name": "chunk_mapping",
                    "schema": {"type": "array"},
                    "required": true,
                    "description": "Mapping of chunk IDs to document metadata for citations"
                }
            ]
        },
        {
            "id": "chat",
            "name": "LLM Chat",
            "step_class": "SimpleChatStep",
            "module": "app.pipeline_steps.simple_chat_step",
            "config": {
                "temperature": 0.7,
                "max_tokens": 500
            },
            "inputs": [
                {
                    "name": "message",
                    "source": "{parameters.message}",
                    "schema": {"type": "string"},
                    "required": true
                },
                {
                    "name": "chat_history",
                    "source": "{steps.fetch_history.output.chat_history}",
                    "schema": {"type": "array"},
                    "required": true
                },
                {
                    "name": "system_prompt",
                    "source": "{parameters.system_prompt}",
                    "schema": {"type": "string"},
                    "required": false
                },
                {
                    "name": "document_context",
                    "source": "{steps.fetch_documents.output.document_context}",
                    "schema": {"type": "string"},
                    "required": false
                },
                {
                    "name": "document_count",
                    "source": "{steps.fetch_documents.output.document_count}",
                    "schema": {"type": "integer"},
                    "required": false
                },
                {
                    "name": "chunk_mapping",
                    "source": "{steps.fetch_documents.output.chunk_mapping}",
                    "schema": {"type": "array"},
                    "required": false
                }
            ],
            "outputs": [
                {
                    "name": "response",
                    "schema": {"type": "string"},
                    "required": true,
                    "description": "LLM-generated response"
                },
                {
                    "name": "metadata",
                    "schema": {"type": "object"},
                    "required": true,
                    "description": "Response metadata (provider, model, tokens, cost)"
                }
            ]
        },
        {
            "id": "generate_title",
            "name": "Generate Chat Title",
            "step_class": "TitleGenerationStep",
            "module": "app.pipeline_steps.title_generation_step",
            "config": {
                "temperature": 0.3,
                "max_tokens": 20
            },
            "inputs": [
                {
                    "name": "message",
                    "source": "{parameters.message}",
                    "schema": {"type": "string"},
                    "required": true
                }
            ],
            "outputs": [
                {
                    "name": "title",
                    "schema": {"type": "string"},
                    "required": true,
                    "description": "LLM-generated chat title (3-6 words)"
                },
                {
                    "name": "title_metadata",
                    "schema": {"type": "object"},
                    "required": true,
                    "description": "Title generation metadata"
                }
            ]
        }
    ],
    "flow": {
        "start_at": "fetch_history",
        "paths": [
            {
                "from": "fetch_history",
                "to": "fetch_documents",
                "condition": {"type": "always"}
            },
            {
                "from": "fetch_documents",
                "to": "chat",
                "condition": {"type": "always"}
            },
            {
                "from": "fetch_documents",
                "to": "generate_title",
                "condition": {
                    "type": "expression",
                    "config": {
                        "source": "fetch_history.is_first_message",
                        "operator": "equals",
                        "value": true
                    }
                }
            }
        ]
    }
}
